---
layout: post
title: Development Schedule
category: dev
---
{% include JB/setup %}

| Release | Module| Feature | Status |
|---------|---------|-------------|--------|
| 0.1 August    | Neural Network |1.1. Feed forward neural network, including CNN, MLP | done|
| |          |1.2. RBM-like model, including RBM | testing|
|         |                |1.3. Recurrent neural network, including standard RNN | working|
|         | Architecture   |1.4. One worker group on single node (with data partition)| done|
|         |                |1.5. Multi worker groups on single node using [Hogwild](http://www.eecs.berkeley.edu/~brecht/papers/hogwildTR.pdf)|done|
|         |                |1.6. Distributed Hogwild|testing|
|         |                |1.7. Multi groups across nodes, like [Downpour](http://papers.nips.cc/paper/4687-large-scale-distributed-deep-networks)|done|
|         |                |1.8. All-Reduce training architecture like [DeepImage](http://arxiv.org/abs/1501.02876)|done|
|         | Failure recovery|1.10. Checkpoint and restore |done|
|         | Tools|1.11. Installation with GNU auto tools| done|
|0.2 October  | Neural Network |2.1. Feed forward neural network, including auto-encoders, hinge loss layers, HDFS data layers||
| |                |2.2. RBM-like model, including DBM | |
|         |                |2.3. Recurrent neural network, including LSTM| |
|         |                |2.4. Model partition ||
|         | Communication  |2.5. MPI||
|         | GPU            |2.6. Single GPU ||
|         |                |2.7. Multiple GPUs on single node||
|         | Resource Management |1.9. Integration with Mesos ||
|         | Architecture   |2.8. Update to support GPUs
|         | Fault Tolerance|2.9. Node failure detection and recovery||
|         | Binding        |2.9. Python binding ||
|         | User Interface |2.10. Web front-end for job submission and performance visualization||
