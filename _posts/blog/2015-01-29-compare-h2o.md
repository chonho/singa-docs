---
layout: post
title: Comparison With H2O
category : development
tagline:
tags : [development, H2O]
---
{% include JB/setup %}
## H2O
[H2O](http://0xdata.com/h2o/) claims to be the world's fastest in-memory platform
for machine learning and predictive analysis. H2O platform consists of a distributed
in-memory key-value store optimized towards machine learning tasks, i.e. columnar
store. H2O execution engine implements a simplified map-reduce model --- distribute
fork-join, to be more precise. A task is recursively split into sub-tasks which
carry out the _map_ functions, then the results are rolled up by the _reduce_
function. Note that this is not the same as the Hadoop's MapReduce execution model.

H2O platform consists of many H2O nodes communicating in P2P manner. A H2O cluster can be started in two ways:

1. A client starts with a _flat file_ containing address of its peers. Each node
    launches a JVM running H2O application, then it finds other nodes using the flat file to establish the cluster.

2. A client requests a number of nodes from a cluster resource manager, i.e.
    YARN. Once given the resources, H2O runs as applications within those nodes,
    and find each other through YARN to establish the cluster. Note that the H2O
    cluster (or cloud) is managed independently by H2O, YARN plays no role.

H2O is written in Java, but also exports Scala, R and REST API.

**Note on Spark+H2O:** Recently Spark teamed up with H2O to develop Sparkling
    Water [h2o-spark](https://github.com/h2oai/sparkling-water) --- an effort to
    integrate H2O into Spark environment. The project essentially provides a
    conversion between H2O's core data structure, i.e. Frame, and Spark's RDDs.
    The result is that Spark applications can now invoke H2O as another library,
    hence extending the Spark ecosystem to support machine learning tasks. Likewise,
    H2O application developers can now take advantage of Spark data pipeline to link up H2O to more complex systems.

### Getting H2O

The easiest way to get H2O is to download [h2o-dev](https://github.com/h2oai/h2o-dev)
    from github and build it following the instruction. Two important jar files
    are `h2o.jar` and `h2o-hadoop.jar`.

### Starting H2O cloud on YARN

Assume that a YARN cluster is up and running. The following creates a new H2O
cluster with 4 nodes, each with 2g of RAM.

    hadoop jar h2o-hadoop.jar water.hadoop.h2odriver -libjars h2o.jar -mapperXmx 2g -nodes 4 -output h2o

The output would be something like:

    Job name 'H2O_42609' submitted
    JobTracker job ID is 'job_1422322695261_0063'
    For YARN users, logs command is 'yarn logs -applicationId application_1422322695261_0063'
    Waiting for H2O cluster to come up...
    H2O node 192.168.22.11:54323 reports H2O cluster size 1
    H2O node 192.168.22.17:54323 reports H2O cluster size 1
    ...
    H2O node 192.168.22.17:54323 reports H2O cluster size 4
    H2O cluster (4 nodes) is up

Note that the cloud name is `H2O_42609`.

### Starting Sparkling Water cloud on YARN
Spark can work on top of YARN, in which Sparkling Water executes inside Spark's
_executors_ (which are  MapReduce containers). To start a Sparkling Water cloud,
one must first create a Spark cluster with the required number of executors.
Below shows how to launch 4-node Spark cluster with an interactive shell:

    spark-shell --master yarn-client --number-executors 4 --driver-memory 4g \
          --executor-memory 2g --jars sparkline-water-assembly.jar,spark-assembly.jar

Inside the spark shell:

    import org.apache.spark.h2o._
    val h2oContext = new H2OContext(sc).start(4)

The result of this will be:

    Sparkling Water Context:

    * number of executors: 4
    * list of used executors:
    (executorId, host, port)
    ------------------------
    (2,host1,54323)
    (1,host2,54327)
    (4,host3,54325)
    (3,host4,54321)
    ------------------------


## MLP on H2O
We build MLP deep learning model on H2O and compares it against SINGA. The
model is trained and tested using [MINST](http://yann.lecun.com/exdb/mnist/). There are 3 main steps:

1. Read and parse the data in to Frame. Data is stored in HDFS, and of CSV format.
2. Build model by configuring `DeepLearningModel.DeepLearningParameters` object.
3. Create `DeepLearning` object given the model, and call `trainModel().get()`.

### Java version
We implemented a client application connecting to the H2O cloud. Its main steps are explained below:

    // connect to the cloud
    H2OClientApp.main(args); // args must contain the flag "-name H2O_xxxx"
    H2O.waitForCloudSize(4,1000); //1000 is the waiting time

    //set up HDFS connection to read data
    Configuration conf = new Configuration();
    conf.addResource(new Path("path_to_core-site.xml"));
    conf.addResource(new Path("path_to_hdfs-site.xml"));
    FileSystem fs = FileSystem.get(conf);

    //read and parse to Frame
    Path train_file = new Path("hdfs://namenode/<file>");
    Frame train_frame = ParseDataset.parse(Key.make(),HDFSFileVec.make(fs.getFileLinkStatus(train_file)));
    ...

    //build model
    DeepLearningParameters dlParams = new DeepLearningParameters();
    dlParams._train = train_frame._key;
    ...
    dlParams._activation = Activation.Tanh;
    ...

    //start training
    new DeepLearning(dlParams).trainModel().get();

The complete source code can be found [here (MLP.java)](http://www.comp.nus.edu.sg/~dinhtta/MLP.java), and run as below:

    java -cp .:h2o.jar MLP -name H2O_xxxx


### Sparkling Water version
We also implemented a Sparkling-Water version of MLP, its Scala source code can
be downloaded [here (mlp.scala)](http://www.comp.nus.edu.sg/~dinhtta/mlp.scala).
The code needs to be build into jar using `sbt`. Once done, it can be submitted
to run on YARN cluster as below:

    spark-submit --class "Simple" --master yarn-client --num-executors 4 \
          --driver-memory 4g --executor-memory 2g  --jars \
          assembly/build/libs/sparkling-water-assembly-0.2.4-65-all.jar,\
          spark-assembly-1.2.0-hadoop2.4.0.jar,guava-18.0.jar  mlp.jar 4

### H2O Performance
We instrumented H2O codebase to measure map and reduce execution time for each
tasks. The jar file can be downloaded [here (h2o.jar)](http://www.comp.nus.edu.sg/~dinhtta/h2o.jar).

Experiments are carried out on our `awan` cluster, each with quad-core Xeon 2.4GHz
CPU, 8GB RAM and 1Gbps network. We vary the number of H2O nodes and the batch
size (i.e. number_of_samples_per_iteration parameter).

**Overall throughput.**

<img src="{{ BASE_PATH }}/assets/image/history/h2o-spark.png" width="500px" />

The figure shows that the throughput, measured as number of samples trained per
second, increases with the number of nodes (`n`). This demonstrates scalability.
Another observation is that the batch size (`b`) does not impact the overall
throughputs. In fact, for 16 nodes the throughput peaks at 128 samples/sec.

**Low-level training performance.**

<img src="{{ BASE_PATH }}/assets/image/history/h2o-spark-worker.png" width="500px"/>

Because the overall throughputs scales well with the number of nodes, it suggests
that the communication cost (which increases with more nodes) is small compared
to the computation cost. To investigate the latter, we measure the performance
of map functions which train the model over some inputs (reduce functions takes
negligible time). This figure shows that the throughput per mapper/worker of H2O is small.
In other words, it is CPU-Bounded.
The throughput for SINGA decreases fast when the cluster size increases.
This is due to the increasing of communication cost from transferring parameters
and gradients. Need to optimize the parameter servers for SINGA to scale it well.

### Update

Arno Candel from H2O team has given a detailed [H2O benchmark](http://h2o.ai/blog/2015/02/deep-learning-performance/)
using our [workload]({{ BASE_PATH }}{% post_url /docs/2015-01-10-quick-start %}).
Their main finding is that H2O throughput on a single node is at least `4x` higher than what we
report here. The blog made several interesting suggestions, e.g., scalability
test in terms of convergence time, and corrected minor
configuration errors in our previous benchmark for H2O.

The convergence rate (time)
is determined by many factors, e.g., the parameter synchronization protocol
between nodes, layer settings (activation function, layer size), learning rate
and etc. In our benchmark, we use the same values of all factors that affect
the convergence rate for both H2O and SINGA, thus
the final convergence time is then mainly affected by the throughput in terms of
number of samples (images) processed per second.

We first update the configuration and re-run experiments to see whether the configuration
modification helps improve the training throughput on a single node.
We will do comparison on scalability in terms of time to convergence later.
Our results confirm that the new configuration does not help, and that we are unable to reach
`4x` improvement of throughput to our previously reported numbers on a single node.

**Note:** We'd like to clarify that our instrumented `H2O.jar` file (downloadable
<a href="http://www.comp.nus.edu.sg/~dinhtta/h2o.jar">here</a>) is the original jar
file with added log messages which print out the time spent on the map and
reduce functions. In the following experiments, we reverted back to the original
jar file compiled from source.

We made 2 modifications to our previous model configuration for H2O:

* <code>_convert_to_enum</code> is set to <code>true</code>
* Remove the final layer, i.e. there are now only 5 hidden layers.

        dlParams._hidden = new int[] {2500,2000,1500,1000,500};
        dlParams._convert_to_enum = true;

The new driver program can be [downloaded (NewMLP.java)](http://www.comp.nus.edu.sg/~dinhtta/NewMLP.java)

#### Results

We ran the single-node experiments on 3 different types of hardware (one of which,
i.e. Xeon x3430@2.4Ghz was used in our previous results). We refer to our previously
used model as _Old Model_ and the modified one as _New Model_.  The numbers
reported below are averaged over 3 runs.

  Hardware | Old model (_samples/sec_) | New model (_samples/sec_) | Running log
  :---|:---|:---|:---
  Xeon x3430@2.4GHz, 8GB RAM | 15.12 | 16.07 | <a href="http://www.comp.nus.edu.sg/~dinhtta/x3430.zip">x3430.zip</a>
  Xeon e3122@3.1GHz, 8GB RAM | 22.22 | 21.88 | <a href="http://www.comp.nus.edu.sg/~dinhtta/e3122.zip">e3122.zip</a>
  Xeon e3127@3.5GHz, 16GB RAM | 33.56 | 34.42 | <a href="http://www.comp.nus.edu.sg/~dinhtta/e3127.zip">e3127.zip</a>

We also run H2O through the web interface, the results on `Xeon e3122@3.1GHz, 8GB RAM `
is about 27 samples/sec. See the **[report]({{ BASE_PATH }}/assets/file/h2o.txt)** generated by H2O.

#### Observations

* The new model does not affect throughput. And we are unable to reach
  <code>75 samples/sec</code> as reported in the H2O blog.

* CPU is the main bottleneck, hence faster CPU leads to higher throughput.
  Thus, it may be possible to reach `4x` higher performance with better
  CPU than what we have available.

* Memory is not the bottleneck in this benchmark. We tried to set memory per
  H2O node from 2-6GB, but the results are the same.

